---
title: "assignment 2"
author: "Rithin"
date: "3/3/2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r}
library(keras)

imdbdir <- "D:/spring 2020/advanced ml/aclImdb"
traindir <- file.path(imdbdir, "train")
labels <- c()
texts <- c()
for (label_type in c("neg", "pos")) {
  label <- switch(label_type, neg = 0, pos = 1)
  dir_name <- file.path(traindir, label_type)
  for (fname in list.files(dir_name, pattern = glob2rx("*.txt"),
                           full.names = TRUE)) {
    texts <- c(texts, readChar(fname, file.info(fname)$size))
    labels <- c(labels, label)
  }
}
```

## Tokenizing data ##

```{r}
maxlen <- 150 
#  Cutting reviews after 150 words
training_samples <- 100  
#  Training on 100 samples
validation_samples <- 10000  
# Validating on 10000 samples
max_words <- 10000
# setting a cutoff limit of top 10000 words.

tokenizer <- text_tokenizer(num_words = max_words) %>% 
  fit_text_tokenizer(texts)

sequences <- texts_to_sequences(tokenizer, texts)
word_index = tokenizer$word_index

cat("Found", length(word_index), "unique tokens.\n")
data <- pad_sequences(sequences, maxlen = maxlen)
y_data <- as.array(labels)
labels <- as.array(labels)
cat("Shape of data tensor:", dim(data), "\n")
cat('Shape of label tensor:', dim(labels), "\n")
```

## Splitting the data ##

```{r}
set.seed(123)
indices <- sample(1:nrow(data))
training_indices <- indices[1:training_samples]
validation_indices <- indices[(training_samples + 1): 
                                (training_samples + validation_samples)]

x_train <- data[training_indices,]
y_train <- labels[training_indices]

x_val <- data[validation_indices,]
y_val <- labels[validation_indices]
```

##  Pre processing the embedding ##
```{r}
glove_dir = 'D:/spring 2020/advanced ml'
lines <- readLines('D:/spring 2020/advanced ml/glove.6B.100d.txt')

embeddings_index <- new.env(hash = TRUE, parent = emptyenv())
for (i in 1:length(lines)) {
  line <- lines[[i]]
  values <- strsplit(line, " ")[[1]]
  word <- values[[1]]
  embeddings_index[[word]] <- as.double(values[-1])
}

cat("Found", length(embeddings_index), "word vectors.\n")

embedding_dim <- 100
embedding_matrix <- array(0, c(max_words, embedding_dim))

for (word in names(word_index)) {
  index <- word_index[[word]]
  if (index < max_words) {
    embedding_vector <- embeddings_index[[word]]
    if (!is.null(embedding_vector))
      embedding_matrix[index+1,] <- embedding_vector
  }
}
```

## Training a model 1 ##
```{r}
model <- keras_model_sequential() %>% 
  layer_embedding(input_dim = max_words, output_dim = embedding_dim, 
                  input_length = maxlen) %>% 
  layer_flatten() %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

summary(model)

# Load the pretrained glove embeddings in the model
get_layer(model, index = 1) %>% 
  set_weights(list(embedding_matrix)) %>% 
  freeze_weights()

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("acc")
)

# evaluating training model
history <- model %>% fit(
  x_train, y_train,
  epochs = 20,
  batch_size = 32,
  validation_data = list(x_val, y_val)
)
plot(history)
## Validation accuracy is 56.5%
```

## Evulation on model 1
```{r}
#evaluating on test data
model %>% fit(
  x_train,
  y_train,
  epochs = 2,
  batch_size = 32)
result <- model %>%  evaluate(data,y_data)
result
```

## using embedded layer ##

```{r}
# Using an embedding layer and classifier on the IMDB data
model <- keras_model_sequential() %>% 
  layer_embedding(input_dim = max_words, output_dim = embedding_dim, 
                  input_length = maxlen) %>% 
  layer_flatten() %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("acc")
)

history1 <- model %>% fit(
  x_train, y_train,
  epochs = 20,
  batch_size = 32,
  validation_data = list(x_val, y_val)
)

plot(history1)
# Validation accuracy is 55.81
```

## Evualation on testing data ##

```{r}
# Evaluating the testing data
model %>% fit(
  x_train,
  y_train,
  epochs = 2,
  batch_size = 32)
res1 <- model %>%  evaluate(data,y_data)
res1
# Test accuracy is 51%

## model accuracy is almost similar on both models when we take fewer samples.
## Model performance depends on the number of samples we consider.
```

